{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O8Nr-gTrmAA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0jaCEmWp6nu"
      },
      "outputs": [],
      "source": [
        "pip install google-play-scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSYyZnEir1L1"
      },
      "outputs": [],
      "source": [
        "# Escolhemos a biblioteca google_play_scrapper para fazer o scrapping do google play\n",
        "\n",
        "from google_play_scraper import app "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISGMYOYsK7t"
      },
      "outputs": [],
      "source": [
        "#A função reviews_all retorna todas as avaliações do app.\n",
        "\n",
        "from google_play_scraper import Sort, reviews_all "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKQPXp9TsOwJ"
      },
      "outputs": [],
      "source": [
        "# Com o ID do AG0 na Google Play Store podemos utilizar a função reviews_all\n",
        "\n",
        "avaliacoes = reviews_all( 'com.safra.safrawallet', lang = 'pt', country = 'br', sort = Sort.MOST_RELEVANT, sleep_milliseconds = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86_IsdhAsZps"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(avaliacoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUIPL88kssoj"
      },
      "outputs": [],
      "source": [
        "import nltk #NLTK é uma biblioteca usada para trabalhar com dados de linguagem humana.\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlI03ET3sxVT"
      },
      "outputs": [],
      "source": [
        "# A função word_tokenize é utilizada para dividir uma determinada frase em palavras\n",
        "\n",
        "df['conteudo'] = df.apply(lambda row: nltk.word_tokenize(row['conteudo']), axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51IB3-G9tHAo"
      },
      "outputs": [],
      "source": [
        "# Remover as \"Stopwords\", palavras comumente usadas, como \"o\", \"um\", \"uma)\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords') \n",
        "language = 'portuguese'\n",
        "\n",
        "stopwords = stopwords.words(language)\n",
        "stopwords = list(set(stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSj0tid6tNwc"
      },
      "outputs": [],
      "source": [
        "# Função para remover as Stopwords das palavras tokenizadas\n",
        "\n",
        "def remover_stopwords(palavras):\n",
        "    lista_palavras = []\n",
        "    for palavra in palavras:\n",
        "        if palavra not in stopwords:\n",
        "            lista_palavras.append(palavra)\n",
        "    return lista_palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBQqVZHttP29"
      },
      "outputs": [],
      "source": [
        "# Função para mudar palavras para lowercase\n",
        "\n",
        "def para_minuscula(palavras):\n",
        "    \"\"\"converter todos os caracteres para lowercase\"\"\"\n",
        "    lista_palavras = []\n",
        "    for palavra in palavras:\n",
        "        nova_palavra = palavra.lower()\n",
        "        lista_palavras.append(nova_palavra)\n",
        "    return lista_palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5uimIzatSu1"
      },
      "outputs": [],
      "source": [
        "# Função para remover pontuação\n",
        "\n",
        "def remover_pontuacao(words):\n",
        "    \"\"\"remover pontuação\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il6GdS__tkrk"
      },
      "outputs": [],
      "source": [
        "# Função para aplicar todas as funções acima.\n",
        "\n",
        "def normalize(words):\n",
        "    words = para_minuscula(words)\n",
        "    words = remover_pontuacao(words)\n",
        "    words = remover_stopwords(words)\n",
        "    \n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V-mHqbwtpnE"
      },
      "outputs": [],
      "source": [
        "# Aplicar nossa limpeza de dados em todas as linhas da coluna conteudo\n",
        "\n",
        "df['conteudo'] = df.apply(lambda row: normalize(row['conteudo']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrq_vvUyueMH"
      },
      "outputs": [],
      "source": [
        "# Vamos utilizar o documento 'sentimentos.txt' que é um um dicionário de sentimos open source obtida no github.\n",
        "\n",
        "sentimentos = open('sentimentos.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zsPThwucxSDY"
      },
      "outputs": [],
      "source": [
        "# Obter a contagem de palavras das reviews do AG0 que estejam contidadas no documento sentimentos.txt\n",
        "\n",
        "d = dict() \n",
        "for linha in df['conteudo']: \n",
        "    linha = linha.strip() \n",
        "    linha = linha.lower()\n",
        "    palavras = linha.split(\" \") \n",
        "    \n",
        "    for palavra in palavras: \n",
        "      if palavra in d: \n",
        "              d[palavra] = d[palavra] + 1\n",
        "      else: \n",
        "              d[palavra] = 1\n",
        "d = sorted(d.items(), key=lambda x: x[1], reverse = True)\n",
        "for i in d:\n",
        "  if i[0] in sentimentos:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8_Tr13luxRa"
      },
      "outputs": [],
      "source": [
        "dic_palavra_polaridade = {}\n",
        "for i in sentimentos.readlines():\n",
        "  pos_ponto = i.find('.')\n",
        "  palavra = (i[:pos_ponto])\n",
        "  pol_pos = i.find('POL')\n",
        "  polaridade = (i[pol_pos+7:pol_pos+9]).replace(';', '')\n",
        "  dic_palavra_polaridade[palavra] = polaridade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb3GCGHGvSUP"
      },
      "outputs": [],
      "source": [
        "def Score_sentimento(frase):\n",
        "    frase = frase.lower()\n",
        "    l_sentimento = []\n",
        "    for p in frase.split():\n",
        "        l_sentimento.append(int(dic_palavra_polaridade.get(p, 0)))\n",
        "    score = sum(l_sentimento)\n",
        "    if score > 0:\n",
        "        return 'Pos {} '.format(score)\n",
        "    elif score == 0:\n",
        "        return 'Neu {} '.format(score)\n",
        "    else:\n",
        "        return 'Neg {}'.format(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKeMrMg_vYzb"
      },
      "outputs": [],
      "source": [
        "df['sentimento'] = df.apply(lambda row: Score_sentimento(row['content']), axis=1)\n",
        "df['Score_Sentimento'] = df['sentimento'].str.slice(-2)\n",
        "df['Score_Sentimento'] =df['Score_Sentimento'].astype(int)\n",
        "df['Sent'] = df['sentimento'].str.slice(0,-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLlc2YZhwI8K"
      },
      "outputs": [],
      "source": [
        "df.groupby('Score_Sentimento').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnY483sUx82p"
      },
      "outputs": [],
      "source": [
        "content = df['content']\n",
        "df['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piZtajRZx_cs"
      },
      "outputs": [],
      "source": [
        "all_content = \" \".join(c for c in content)\n",
        "all_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufbes1NU2udo"
      },
      "outputs": [],
      "source": [
        "print(palavra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW01nrWiyCOY"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUyHegaNyDc_"
      },
      "outputs": [],
      "source": [
        "stopwords = set(STOPWORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDUQ3B0wyQ0s"
      },
      "outputs": [],
      "source": [
        "stopwords.update([\"pra\", \"app\", \"aplicativo\", \"vc\", \"pra\", \"to\", \"os\", \"vcs\", \"nao\", \"pq\", \"mim\", \"ai\", \"ta\", \"ja\", \"ter\", \"fazer\", \"lá\", \"deu\", \"dado\", \"então\", \"vou\", \"vai\", \"veze\", \"ficar\", \"tá\", \"apena\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDuxqvvBydhH"
      },
      "outputs": [],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Qlaf3cy25I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2IvzG83yaM4"
      },
      "outputs": [],
      "source": [
        "#Criando o objeto wordcloud com as configs necessárias. Cor escolhida = preta, origem dos dados = all_content\n",
        "wordcloud = WordCloud(stopwords=stopwords,\n",
        "                      background_color='black', width=1600,                            \n",
        "                      \n",
        "                      height=800).generate(all_content)\n",
        "\n",
        "#configurando forma de apresentação do gráfico e apresentando no notebook.\n",
        "fig, ax = plt.subplots(figsize=(16,8))            \n",
        "ax.imshow(wordcloud, interpolation='bilinear')       \n",
        "ax.set_axis_off()\n",
        "plt.imshow(wordcloud)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}